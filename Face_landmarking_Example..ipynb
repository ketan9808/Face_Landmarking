{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The detector is used to detect face in the captured frame. Feel free to use your own model here\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# The predictor will output the face landmarks\n",
    "predictor_68 = dlib.shape_predictor('./Models/shape_predictor_68_face_landmarks.dat')\n",
    "predictor_5 = dlib.shape_predictor('./Models/shape_predictor_5_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use path to video \n",
    "# or index of mounted camers \n",
    "# or use ip address(IPWebcam app) inplace of 0\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "numbers_toggle = True\n",
    "model_toggle = True\n",
    "\n",
    "while True:\n",
    "    _, frame = cam.read()# Frame size is 640x48\n",
    "#     frame = cv2.resize(frame, (400,400))\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    rects = detector(gray, 0) #how many faces are available and their coordinates\n",
    "    \n",
    "    if len(rects) > 0:\n",
    "        text = \"{} face(s) found\".format(len(rects))\n",
    "        cv2.putText(frame, text, (10, 20), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5, (0, 0, 255), 2)\n",
    "        \n",
    "    for rect in rects:\n",
    "# The rect object has 4 attributes left, top, right, bottom ==> rect_to_bb() ==> [x, y, width, height]\n",
    "        (bX, bY, bW, bH) = face_utils.rect_to_bb(rect)\n",
    "        cv2.rectangle(frame, (bX, bY), (bX + bW, bY + bH),(0, 255, 0), 1)\n",
    "\n",
    "# face object which contain the landmark predictions\n",
    "        if model_toggle == True:\n",
    "            shape = predictor_68(gray, rect)\n",
    "        else:\n",
    "            shape = predictor_5(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "# shape object contain attributes part(i).x and .part(i).y ==> shape_to_np() ==> ndarray[(xi, yi)]        \n",
    "\n",
    "        for (i, (x, y)) in enumerate(shape):\n",
    "            cv2.circle(frame, (x, y), 1, (0, 0, 255), -1)\n",
    "            if numbers_toggle == True:\n",
    "                cv2.putText(frame, str(i + 1), (x - 10, y - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "    elif key == ord(\"n\"):\n",
    "        numbers_toggle = not numbers_toggle\n",
    "    elif key == ord('m'):\n",
    "        model_toggle = not model_toggle\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
